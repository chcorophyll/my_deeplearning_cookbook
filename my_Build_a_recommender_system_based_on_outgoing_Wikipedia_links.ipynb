{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_Build a recommender system based on outgoing Wikipedia links.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chcorophyll/my_deeplearning_cookbook/blob/master/my_Build_a_recommender_system_based_on_outgoing_Wikipedia_links.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoOF9WaRDh_z",
        "colab_type": "code",
        "outputId": "d78a93cb-b786-45a4-f472-47cb9e323fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!git clone https://github.com/chcorophyll/deep_learning_cookbook.git"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep_learning_cookbook'...\n",
            "remote: Enumerating objects: 427, done.\u001b[K\n",
            "remote: Total 427 (delta 0), reused 0 (delta 0), pack-reused 427\u001b[K\n",
            "Receiving objects: 100% (427/427), 160.26 MiB | 35.34 MiB/s, done.\n",
            "Resolving deltas: 100% (207/207), done.\n",
            "Checking out files: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYnVKt30D8Vm",
        "colab_type": "code",
        "outputId": "07442bc9-1dbf-4515-f64f-9746b0d02f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'03.1 Using pre trained word embeddings.ipynb'\n",
            "'03.2 Domain specific ranking using word2vec cosine distance.ipynb'\n",
            "'04.1 Collect movie data from Wikipedia.ipynb'\n",
            "'04.2 Build a recommender system based on outgoing Wikipedia links.ipynb'\n",
            "'05.1 Generating Text in the Style of an Example Text.ipynb'\n",
            "'06.1 Question matching.ipynb'\n",
            "'07.1 Text Classification.ipynb'\n",
            "'07.2 Emoji Suggestions.ipynb'\n",
            "'07.3 Tweet Embeddings.ipynb'\n",
            "'08.1 Sequence to sequence mapping.ipynb'\n",
            "'08.2 Import Gutenberg.ipynb'\n",
            "'08.3 Subword tokenizing.ipynb'\n",
            "'09.1 Reusing a pretrained image recognition network.ipynb'\n",
            "'09.2 Images as embeddings.ipynb'\n",
            "'09.3 Retraining.ipynb'\n",
            "'10.1 Building an inverse image search service.ipynb'\n",
            "'11.1 Detecting Multiple Images.ipynb'\n",
            "'12.1 Activation Optimization.ipynb'\n",
            "'12.2 Neural Style.ipynb'\n",
            "'13.1 Quick Draw Cat Autoencoder.ipynb'\n",
            "'13.2 Variational Autoencoder.ipynb'\n",
            "'13.5 Quick Draw Autoencoder.ipynb'\n",
            "'14.1 Importing icons.ipynb'\n",
            "'14.2 Icon Autoencoding.ipynb'\n",
            "'14.2 Variational Autoencoder Icons.ipynb'\n",
            "'14.3 Icon GAN.ipynb'\n",
            "'14.4 Icon RNN.ipynb'\n",
            "'15.1 Song Classification.ipynb'\n",
            "'15.2 Index Local MP3s.ipynb'\n",
            "'15.3 Spotify Playlists.ipynb'\n",
            "'15.4 Train a music recommender.ipynb'\n",
            "'16.1 Productionize Embeddings.ipynb'\n",
            "'16.2 Prepare Keras model for Tensorflow Serving.ipynb'\n",
            "'16.3 Prepare model for iOS.ipynb'\n",
            "'16.4 Simple Text Generation.ipynb'\n",
            " data\n",
            " deep_learning_cookbook\n",
            " export_keras_to_tensor_flow_serving.py\n",
            " keras_js\n",
            " keras_server.py\n",
            " LICENSE\n",
            " nb_utils.py\n",
            " README.md\n",
            " requirements.in\n",
            " requirements.txt\n",
            " seq2seq_server.py\n",
            "'Simple Seq2Seq.ipynb'\n",
            " simple_server.py\n",
            " style_transfer\n",
            " zoo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VA8WXHPD9qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "path_o = os.getcwd()\n",
        "data_path = os.path.join(path_o, \"deep_learning_cookbook\")\n",
        "os.chdir(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkbWD0EPESGQ",
        "colab_type": "code",
        "outputId": "bded1a50-198b-46be-b1ca-16e83ce1bc0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'03.1 Using pre trained word embeddings.ipynb'\n",
            "'03.2 Domain specific ranking using word2vec cosine distance.ipynb'\n",
            "'04.1 Collect movie data from Wikipedia.ipynb'\n",
            "'04.2 Build a recommender system based on outgoing Wikipedia links.ipynb'\n",
            "'05.1 Generating Text in the Style of an Example Text.ipynb'\n",
            "'06.1 Question matching.ipynb'\n",
            "'07.1 Text Classification.ipynb'\n",
            "'07.2 Emoji Suggestions.ipynb'\n",
            "'07.3 Tweet Embeddings.ipynb'\n",
            "'08.1 Sequence to sequence mapping.ipynb'\n",
            "'08.2 Import Gutenberg.ipynb'\n",
            "'08.3 Subword tokenizing.ipynb'\n",
            "'09.1 Reusing a pretrained image recognition network.ipynb'\n",
            "'09.2 Images as embeddings.ipynb'\n",
            "'09.3 Retraining.ipynb'\n",
            "'10.1 Building an inverse image search service.ipynb'\n",
            "'11.1 Detecting Multiple Images.ipynb'\n",
            "'12.1 Activation Optimization.ipynb'\n",
            "'12.2 Neural Style.ipynb'\n",
            "'13.1 Quick Draw Cat Autoencoder.ipynb'\n",
            "'13.2 Variational Autoencoder.ipynb'\n",
            "'13.5 Quick Draw Autoencoder.ipynb'\n",
            "'14.1 Importing icons.ipynb'\n",
            "'14.2 Icon Autoencoding.ipynb'\n",
            "'14.2 Variational Autoencoder Icons.ipynb'\n",
            "'14.3 Icon GAN.ipynb'\n",
            "'14.4 Icon RNN.ipynb'\n",
            "'15.1 Song Classification.ipynb'\n",
            "'15.2 Index Local MP3s.ipynb'\n",
            "'15.3 Spotify Playlists.ipynb'\n",
            "'15.4 Train a music recommender.ipynb'\n",
            "'16.1 Productionize Embeddings.ipynb'\n",
            "'16.2 Prepare Keras model for Tensorflow Serving.ipynb'\n",
            "'16.3 Prepare model for iOS.ipynb'\n",
            "'16.4 Simple Text Generation.ipynb'\n",
            " data\n",
            " export_keras_to_tensor_flow_serving.py\n",
            " keras_js\n",
            " keras_server.py\n",
            " LICENSE\n",
            " nb_utils.py\n",
            " README.md\n",
            " requirements.in\n",
            " requirements.txt\n",
            " seq2seq_server.py\n",
            "'Simple Seq2Seq.ipynb'\n",
            " simple_server.py\n",
            " style_transfer\n",
            " zoo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_MNdliZEXwT",
        "colab_type": "text"
      },
      "source": [
        "**Collect movie data from Wikipedia**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdLPq92-FlYT",
        "colab_type": "code",
        "outputId": "562746b0-2365-4018-a2dc-498f7ecafb39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "!pip install mwparserfromhell"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mwparserfromhell\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/03/4fb04da533c7e237c0104151c028d8bff856293d34e51d208c529696fb79/mwparserfromhell-0.5.4.tar.gz (135kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 4.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mwparserfromhell\n",
            "  Building wheel for mwparserfromhell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/76/d5/7088b941df3b362c45dd7912dd05314bc034751ec9cbca9a75\n",
            "Successfully built mwparserfromhell\n",
            "Installing collected packages: mwparserfromhell\n",
            "Successfully installed mwparserfromhell-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQF--MhTETcV",
        "colab_type": "code",
        "outputId": "53548d03-0eba-45ca-b443-2af391ee20ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import requests \n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import time\n",
        "from keras.utils import get_file\n",
        "try:\n",
        "    from urllib.request import urlretrieve\n",
        "except ImportError:\n",
        "    from urllib import urlretrieve\n",
        "import xml.sax\n",
        "import subprocess\n",
        "import re\n",
        "import mwparserfromhell\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0U5hpDAHYkC",
        "colab_type": "code",
        "outputId": "2f0716fa-626d-4947-8505-52d2c9d7b068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "index = requests.get(\"https://dumps.wikimedia.org/enwiki/\").text\n",
        "soup_index = BeautifulSoup(index, \"html.parser\")\n",
        "dumps = [a['href'] for a in soup_index.find_all(\"a\") \n",
        "         if a.has_attr(\"href\") and a.text[:-1].isdigit()]\n",
        "dumps"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['20190320/',\n",
              " '20190401/',\n",
              " '20190420/',\n",
              " '20190501/',\n",
              " '20190520/',\n",
              " '20190601/',\n",
              " '20190620/']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGLpCoW_JjqO",
        "colab_type": "code",
        "outputId": "a4799421-3fbb-447f-bfa3-c0d335f4abec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "pages_xml = []\n",
        "for dump_url in sorted(dumps, reverse=True):\n",
        "    print(dump_url)\n",
        "    dump_html = index = requests.get('https://dumps.wikimedia.org/enwiki/' + dump_url).text\n",
        "    soup_dump = BeautifulSoup(dump_html, 'html.parser')\n",
        "#     print(soup_dump)\n",
        "    pages_xml += [a['href'] for a in soup_dump.find_all('a') \n",
        "                 if a.has_attr('href') and a['href'].endswith('-pages-articles.xml.bz2')]\n",
        "#     if pages_xml:\n",
        "#         break\n",
        "    time.sleep(0.8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20190620/\n",
            "20190601/\n",
            "20190520/\n",
            "20190501/\n",
            "20190420/\n",
            "20190401/\n",
            "20190320/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBuZ5F2ZPnrr",
        "colab_type": "code",
        "outputId": "ee236aa8-b6ad-4bc7-af9f-277baff4661a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "pages_xml"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/enwiki/20190601/enwiki-20190601-pages-articles.xml.bz2',\n",
              " '/enwiki/20190520/enwiki-20190520-pages-articles.xml.bz2',\n",
              " '/enwiki/20190501/enwiki-20190501-pages-articles.xml.bz2',\n",
              " '/enwiki/20190420/enwiki-20190420-pages-articles.xml.bz2',\n",
              " '/enwiki/20190401/enwiki-20190401-pages-articles.xml.bz2',\n",
              " '/enwiki/20190320/enwiki-20190320-pages-articles.xml.bz2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba9KdulARnS0",
        "colab_type": "code",
        "outputId": "69a3e6fb-83cb-4af6-d447-8c1779a82515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "wikipedia_dump = pages_xml[0].rsplit(\"/\")[-1]\n",
        "url = url = 'https://dumps.wikimedia.org/' + pages_xml[0] \n",
        "path = get_file(wikipedia_dump, url)\n",
        "path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://dumps.wikimedia.org//enwiki/20190601/enwiki-20190601-pages-articles.xml.bz2\n",
            "  658735104/16181808319 [>.............................] - ETA: 2:05:20"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e4411ce19987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwikipedia_dump\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpages_xml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://dumps.wikimedia.org/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpages_xml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwikipedia_dump\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x-Na0TlUzC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_article(title, text):\n",
        "    rotten = [(re.findall(\"\\d\\d?\\d?%\", p), re.findall(\"\\d\\.\\d\\/\\d+|$\", p),\n",
        "               p.lower().find(\"rotten tomatoes\")) for p in text.split(\"\\n\\n\")]\n",
        "    rating = next(((perc[0], rating[0]) for perc, rating, idx \n",
        "                   in rotten if len(perc) == 1 and idx > -1), (None, None))\n",
        "    wikicode = mwparserfromhell.parse(text)\n",
        "    film = next((template for template in wikicode.filter_templates() \n",
        "                 if template.name.strip().lower() == \"infobox film\"), None)\n",
        "    if film:\n",
        "        properties = {param.name.strip_code().strip(): param.value.strip_code().strip() \n",
        "                      for param in film.params\n",
        "                      if param.value.strip_code().strip()}\n",
        "        links = [x.title.strip_code().strip() for x in wikicode.filter_wikilinks()]\n",
        "    return (title, properties, links) + rating"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a7UlfAOQihs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WikiXmlHandler(xml.sax.handler.ContentHandler):\n",
        "    def __init__(self):\n",
        "        xml.sax.handler.ContentHandler.__init__(self)\n",
        "        self._buffer = None\n",
        "        self._values = {}\n",
        "        self._movies = []\n",
        "        self._curent_tag = None\n",
        "\n",
        "    def characters(self, content):\n",
        "        if self._curent_tag:\n",
        "            self._buffer.append(content)\n",
        "\n",
        "    def startElement(self, name, attrs):\n",
        "        if name in ('title', 'text'):\n",
        "            self._curent_tag = name\n",
        "            self._buffer = []\n",
        "\n",
        "    def endElement(self, name):\n",
        "        if name == self._curent_tag:\n",
        "            self._values[name] = ' '.join(self._buffer)\n",
        "\n",
        "        if name == 'page':\n",
        "            movie = process_article(**self._values)\n",
        "            if movie:\n",
        "                self._movies.append(movie)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVOAGcsmRmo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parser = xml.sax.make_parser()\n",
        "handler = WikiXmlHandler()\n",
        "parser.setContentHandler(handler)\n",
        "for line in subprocess.Popen(['bzcat'], stdin=open(path), stdout=subprocess.PIPE).stdout:\n",
        "    try:\n",
        "        parser.feed(line)\n",
        "    except StopIteration:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRqRB3SGSEtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('generated/wp_movies.ndjson', 'wt') as fout:\n",
        "    for movie in handler._movies:\n",
        "         fout.write(json.dumps(movie) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr--Ap2sTHmH",
        "colab_type": "text"
      },
      "source": [
        "** Build a recommender system based on outgoing Wikipedia links**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clt1c_RuTHKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding, Input, Reshape\n",
        "from keras.layers.merge import Dot\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn import svm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfyzMxrbU_1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"data/wp_movies_10k.ndjson\") as fin:\n",
        "    movies = [json.loads(l) for l in fin]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LazF3tX7VUuq",
        "colab_type": "code",
        "outputId": "3dcb240e-a709-457b-b2d4-134eaee1a726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7651
        }
      },
      "source": [
        "movies[0]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Deadpool (film)',\n",
              " {'Software Used': 'Adobe Premier Pro',\n",
              "  'alt': \"Official poster shows the titular hero Deadpool standing in front of the viewers, with hugging his hands, and donning his traditional black and red suit and mask, and the film's name, credits and billing below him.\",\n",
              "  'budget': '$58 million',\n",
              "  'caption': 'Theatrical release poster',\n",
              "  'cinematography': 'Ken Seng',\n",
              "  'country': 'United States',\n",
              "  'director': 'Tim Miller',\n",
              "  'distributor': '20th Century Fox',\n",
              "  'editing': 'Julian Clarke',\n",
              "  'gross': '$783.1 million',\n",
              "  'image': 'Deadpool poster.jpg',\n",
              "  'language': 'English',\n",
              "  'music': 'Tom Holkenborg',\n",
              "  'name': 'Deadpool',\n",
              "  'runtime': '108 minutes'},\n",
              " ['Tim Miller (director)',\n",
              "  'Simon Kinberg',\n",
              "  'Ryan Reynolds',\n",
              "  'Lauren Shuler Donner',\n",
              "  'Rhett Reese',\n",
              "  'Paul Wernick',\n",
              "  'Deadpool',\n",
              "  'Fabian Nicieza',\n",
              "  'Rob Liefeld',\n",
              "  'Morena Baccarin',\n",
              "  'Ed Skrein',\n",
              "  'T.J. Miller',\n",
              "  'Gina Carano',\n",
              "  'Leslie Uggams',\n",
              "  'Brianna Hildebrand',\n",
              "  'Stefan Kapičić',\n",
              "  'Junkie XL',\n",
              "  'Julian Clarke',\n",
              "  'Marvel Entertainment',\n",
              "  'Kinberg Genre',\n",
              "  'Lauren Shuler Donner',\n",
              "  'TSG Entertainment',\n",
              "  '20th Century Fox',\n",
              "  'Le Grand Rex',\n",
              "  'Variety (magazine)',\n",
              "  'Box Office Mojo',\n",
              "  'superhero film',\n",
              "  'Tim Miller (director)',\n",
              "  'Rhett Reese',\n",
              "  'Paul Wernick',\n",
              "  'Marvel Comics',\n",
              "  'Deadpool',\n",
              "  'X-Men (film series)',\n",
              "  'Ryan Reynolds',\n",
              "  'Morena Baccarin',\n",
              "  'Ed Skrein',\n",
              "  'T.J. Miller',\n",
              "  'Gina Carano',\n",
              "  'Leslie Uggams',\n",
              "  'Brianna Hildebrand',\n",
              "  'Stefan Kapičić',\n",
              "  'antihero',\n",
              "  'New Line Cinema',\n",
              "  '20th Century Fox',\n",
              "  'X-Men Origins: Wolverine',\n",
              "  'principal photography',\n",
              "  'Vancouver',\n",
              "  'IMAX',\n",
              "  'Digital Light Processing',\n",
              "  'D-Box Technologies',\n",
              "  'List of accolades received by Deadpool (film)',\n",
              "  'Golden Globe Award',\n",
              "  'Golden Globe Award for Best Motion Picture – Musical or Comedy',\n",
              "  'Golden Globe Award for Best Actor – Motion Picture Musical or Comedy',\n",
              "  'Producers Guild of America Award',\n",
              "  \"Critics' Choice Movie Awards\",\n",
              "  \"Critics' Choice Movie Award for Best Comedy\",\n",
              "  \"Critics' Choice Movie Award for Best Actor in a Comedy\",\n",
              "  '2016 in film',\n",
              "  '#Sequels',\n",
              "  'nonlinear narrative',\n",
              "  'Deadpool',\n",
              "  'special forces',\n",
              "  'Copycat (Marvel Comics)',\n",
              "  'Liver cancer',\n",
              "  'Lung cancer',\n",
              "  'Prostate cancer',\n",
              "  'Brain tumor',\n",
              "  'Ajax (comics)#Deadpool character',\n",
              "  'Angel Dust (comics)',\n",
              "  'healing factor',\n",
              "  'rebar',\n",
              "  'Weasel (Marvel Comics)',\n",
              "  'Blind Al',\n",
              "  'Colossus (comics)',\n",
              "  'Negasonic Teenage Warhead',\n",
              "  'X-Men',\n",
              "  'helicarrier',\n",
              "  'post-credits scene',\n",
              "  'Cable (comics)',\n",
              "  'File:Cast of Deadpool.jpg',\n",
              "  'San Diego Comic-Con',\n",
              "  'Ryan Reynolds',\n",
              "  'Deadpool',\n",
              "  'cancer',\n",
              "  'X-Men Origins: Wolverine',\n",
              "  'fourth wall',\n",
              "  'Morena Baccarin',\n",
              "  'Copycat (Marvel Comics)',\n",
              "  'damsel in distress',\n",
              "  'Ed Skrein',\n",
              "  'Ajax (comics)#Deadpool character',\n",
              "  'Weapon X',\n",
              "  'YouTube',\n",
              "  'Tim Miller (director)',\n",
              "  'T.J. Miller',\n",
              "  'Weasel (Marvel Comics)',\n",
              "  'Simon Kinberg',\n",
              "  'USA Today',\n",
              "  'Gina Carano',\n",
              "  'Angel Dust (comics)',\n",
              "  'Leslie Uggams',\n",
              "  'Blind Al',\n",
              "  'Indiewire',\n",
              "  'Brianna Hildebrand',\n",
              "  'Negasonic Teenage Warhead',\n",
              "  'X-Men',\n",
              "  'Marvel Studios',\n",
              "  'Kevin Feige',\n",
              "  'Ego the Living Planet',\n",
              "  'Guardians of the Galaxy Vol. 2',\n",
              "  'Stefan Kapičić',\n",
              "  'Colossus (comics)',\n",
              "  'Daniel Cudmore',\n",
              "  'X2 (film)',\n",
              "  'X-Men: The Last Stand',\n",
              "  'X-Men: Days of Future Past',\n",
              "  'Andre Tricoteux',\n",
              "  'Karan Soni',\n",
              "  'Jed Rees',\n",
              "  'Agent Smith',\n",
              "  'Stan Lee',\n",
              "  'Rob Liefeld',\n",
              "  'Isaac C. Singleton Jr.',\n",
              "  'Bob, Agent of Hydra',\n",
              "  'Hydra (comics)',\n",
              "  'Nathan Fillion',\n",
              "  'Twitter',\n",
              "  'Simon Kinberg',\n",
              "  'Artisan Entertainment',\n",
              "  'Marvel Entertainment',\n",
              "  'Deadpool',\n",
              "  'New Line Cinema',\n",
              "  'David S. Goyer',\n",
              "  'Ryan Reynolds',\n",
              "  'Shar Pei',\n",
              "  'Cable & Deadpool',\n",
              "  'Turnaround (filmmaking)',\n",
              "  'X-Men Origins: Wolverine',\n",
              "  'Lauren Shuler Donner',\n",
              "  'Reboot (fiction)',\n",
              "  'fourth wall',\n",
              "  'Rhett Reese',\n",
              "  'Paul Wernick',\n",
              "  'Robert Rodriguez',\n",
              "  'Tim Miller (director)',\n",
              "  'Adam Berg (director)',\n",
              "  'Blur Studio',\n",
              "  'James Cameron',\n",
              "  'David Fincher',\n",
              "  'development hell',\n",
              "  'Garrison Kane',\n",
              "  'Cannonball (comics)',\n",
              "  'Computer-generated imagery',\n",
              "  'Hillbilly',\n",
              "  'Wyre (comics)',\n",
              "  'Angel Dust (comics)',\n",
              "  'Cable (comics)',\n",
              "  'List of directorial debuts',\n",
              "  'Colossus (comics)',\n",
              "  'Simon Kinberg',\n",
              "  'The Hollywood Reporter',\n",
              "  'T. J. Miller',\n",
              "  'Ed Skrein',\n",
              "  'Gina Carano',\n",
              "  'Angel Dust (comics)',\n",
              "  'Morena Baccarin',\n",
              "  'Taylor Schilling',\n",
              "  'Crystal Reed',\n",
              "  'Rebecca Rittenhouse',\n",
              "  'Sarah Greene (actress)',\n",
              "  'Jessica De Gouw',\n",
              "  'Weasel (Marvel Comics)',\n",
              "  'Copycat (Marvel Comics)',\n",
              "  'Brianna Hildebrand',\n",
              "  'Negasonic Teenage Warhead',\n",
              "  'Ajax (comics)#Deadpool character',\n",
              "  'Leslie Uggams',\n",
              "  'Blind Al',\n",
              "  'Jed Rees',\n",
              "  'Stefan Kapičić',\n",
              "  'Colossus (comics)',\n",
              "  'Daniel Cudmore',\n",
              "  'Twitter',\n",
              "  'File:Deadpool, Georgia Viaduct, Vancouver, April 6 2015 - 3.jpg',\n",
              "  'Rolling Stone',\n",
              "  'Principal photography',\n",
              "  'Vancouver',\n",
              "  'stunt coordinator',\n",
              "  'CBC News',\n",
              "  'David Cronenberg',\n",
              "  'Eastern Promises',\n",
              "  'Yahoo! Movies',\n",
              "  'Digital Domain',\n",
              "  'Weta Digital',\n",
              "  'Rodeo FX',\n",
              "  'Luma Pictures',\n",
              "  'Image Engine',\n",
              "  'Adobe Systems',\n",
              "  'matte paintings',\n",
              "  'helicarrier',\n",
              "  'Detroit',\n",
              "  'Chicago',\n",
              "  'File:Colossus - mocap.jpg',\n",
              "  'Colossus (comics)',\n",
              "  'Computer-generated imagery',\n",
              "  'Digital Domain',\n",
              "  'Cold-formed steel',\n",
              "  'Hot working',\n",
              "  'Taxicab',\n",
              "  'Junkie XL',\n",
              "  'ARP 2600',\n",
              "  'Synclavier',\n",
              "  'Oberheim Electronics#Oberheim polyphonic synthesizers',\n",
              "  'io9',\n",
              "  'YouTube personality',\n",
              "  'Deadpool (video game)',\n",
              "  'Milan Records',\n",
              "  'Grand Rex',\n",
              "  'IMAX',\n",
              "  'Digital Light Processing',\n",
              "  'D-Box Technologies',\n",
              "  'The Hollywood Reporter',\n",
              "  'Uzbekistan',\n",
              "  'Central Board of Film Certification',\n",
              "  'The Hollywood Reporter',\n",
              "  'Hong Kong',\n",
              "  'Singapore',\n",
              "  'standing ovation',\n",
              "  'The Hollywood Reporter',\n",
              "  'Meta-joke',\n",
              "  'Business Insider',\n",
              "  'viral marketing',\n",
              "  'Christmas',\n",
              "  \"Valentine's Day\",\n",
              "  'io9',\n",
              "  'emoji',\n",
              "  'YouTube',\n",
              "  'Screen Junkies',\n",
              "  'The Guardian',\n",
              "  'Blu-ray',\n",
              "  '2016 in film',\n",
              "  'The Matrix Reloaded',\n",
              "  'Forbes',\n",
              "  'Variety (magazine)',\n",
              "  'X-Men: Days of Future Past',\n",
              "  'Deadline.com',\n",
              "  'James Cameron',\n",
              "  'George Lucas',\n",
              "  'Star Wars: Episode III – Revenge of the Sith',\n",
              "  'The Dark Knight Rises',\n",
              "  'The Hollywood Reporter',\n",
              "  'IMAX',\n",
              "  '3D film',\n",
              "  'Los Angeles Times',\n",
              "  'Yahoo!',\n",
              "  'Variety (magazine)',\n",
              "  'Forbes (magazine)',\n",
              "  \"Presidents' Day (United States)\",\n",
              "  'Zoolander 2',\n",
              "  'How to Be Single',\n",
              "  'The Hollywood Reporter',\n",
              "  'Deadline.com',\n",
              "  'Variety (magazine)',\n",
              "  'Guardians of the Galaxy (film)',\n",
              "  'Captain America: The Winter Soldier',\n",
              "  'The Hollywood Reporter',\n",
              "  'Deadline.com',\n",
              "  'R-rated',\n",
              "  'The Hangover Part II',\n",
              "  'Fifty Shades of Grey (film)',\n",
              "  'The Hollywood Reporter',\n",
              "  'Deadline.com',\n",
              "  'word of mouth',\n",
              "  'Star Wars: Episode III – Revenge of the Sith',\n",
              "  'Forbes',\n",
              "  'Century Theatres',\n",
              "  'Deadline.com',\n",
              "  'The Hollywood Reporter',\n",
              "  'The Avengers (2012 film)',\n",
              "  'The Hunger Games (film)',\n",
              "  'Forbes (magazine)',\n",
              "  'Furious 7',\n",
              "  'Alice in Wonderland (2010 film)',\n",
              "  'Wanted (2008 film)',\n",
              "  'Watchmen (film)',\n",
              "  'The Vow (2012 film)',\n",
              "  'X-Men (film)',\n",
              "  'X-Men: First Class',\n",
              "  'The Wolverine (film)',\n",
              "  'X-Men Origins: Wolverine',\n",
              "  'Deadline.com',\n",
              "  'Second weekend in box office performance',\n",
              "  'Avengers: Age of Ultron',\n",
              "  'X-Men: The Last Stand',\n",
              "  '300 (film)',\n",
              "  'Forbes',\n",
              "  'The Passion of the Christ',\n",
              "  'Forbes',\n",
              "  'Zootopia',\n",
              "  'London Has Fallen',\n",
              "  'Non-Hispanic whites',\n",
              "  'Hispanic',\n",
              "  'African-American',\n",
              "  'Asian Americans',\n",
              "  'Guardians of the Galaxy (film)',\n",
              "  'Captain America: Civil War',\n",
              "  'Avengers: Age of Ultron',\n",
              "  'Batman v Superman: Dawn of Justice',\n",
              "  'Suicide Squad (film)',\n",
              "  'The Hollywood Reporter',\n",
              "  'Spectre (2015)',\n",
              "  'United Kingdom and Ireland',\n",
              "  'Chinese New Year',\n",
              "  'Hong Kong',\n",
              "  'Singapore',\n",
              "  'The Mermaid (2016 film)',\n",
              "  'Deadline.com',\n",
              "  'Ip Man 3',\n",
              "  'Zootopia',\n",
              "  'Iron Man 3',\n",
              "  'Star Wars: The Force Awakens',\n",
              "  'Rotten Tomatoes',\n",
              "  'Rotten Tomatoes',\n",
              "  'Metacritic',\n",
              "  'CinemaScore',\n",
              "  'Peter Travers',\n",
              "  'Rolling Stone',\n",
              "  'Rolling Stone',\n",
              "  'TheWrap',\n",
              "  'Alonso Duralde',\n",
              "  'Guardians of the Galaxy (film)',\n",
              "  'Christy Lemire',\n",
              "  'Richard Roeper',\n",
              "  'Chicago Sun-Times',\n",
              "  'Kenneth Turan',\n",
              "  'Los Angeles Times',\n",
              "  'Los Angeles Times',\n",
              "  'The Hollywood Reporter',\n",
              "  'Deadline.com',\n",
              "  'Spider-Man',\n",
              "  'Superhero Hype',\n",
              "  '/Film',\n",
              "  'Domino (comics)',\n",
              "  'TheWrap',\n",
              "  'Mashable',\n",
              "  'David Leitch (filmmaker)',\n",
              "  'Rupert Sanders',\n",
              "  'Drew Goddard',\n",
              "  'Mashable',\n",
              "  'X-Force',\n",
              "  'Hugh Jackman',\n",
              "  'Twitter',\n",
              "  'Variety (magazine)',\n",
              "  'The Hollywood Reporter',\n",
              "  'British Board of Film Classification',\n",
              "  'Los Angeles Times',\n",
              "  'Variety (magazine)',\n",
              "  'MTV News',\n",
              "  'Empire (film magazine)',\n",
              "  'The Hollywood Reporter',\n",
              "  'Variety (magazine)',\n",
              "  'The Daily Dot',\n",
              "  'Bleeding Cool',\n",
              "  'The Hollywood Reporter',\n",
              "  'TheWrap',\n",
              "  'The Hollywood Reporter',\n",
              "  'Variety (magazine)',\n",
              "  'Entertainment Weekly',\n",
              "  'Deadline.com',\n",
              "  'MTV News',\n",
              "  'Deadline.com',\n",
              "  'Business Insider',\n",
              "  'The Hollywood Reporter',\n",
              "  'Twitter',\n",
              "  'Empire (magazine)',\n",
              "  'fxguide',\n",
              "  'Category:20th Century Fox films',\n",
              "  'Category:2010s action films',\n",
              "  'Category:2010s comedy films',\n",
              "  'Category:2010s superhero films',\n",
              "  'Category:2016 films',\n",
              "  'Category:American action comedy films',\n",
              "  'Category:American black comedy films',\n",
              "  'Category:American films',\n",
              "  'Category:Deadpool',\n",
              "  'Category:Directorial debut films',\n",
              "  'Category:English-language films',\n",
              "  'Category:Film scores by Junkie XL',\n",
              "  'Category:Film spin-offs',\n",
              "  'Category:Films about cancer',\n",
              "  'Category:Films about revenge',\n",
              "  'Category:Films directed by Tim Miller',\n",
              "  'Category:Films set in New York',\n",
              "  'Category:Films shot in Vancouver',\n",
              "  'Category:Films with live action and animation',\n",
              "  'Category:Human experimentation in fiction',\n",
              "  'Category:IMAX films',\n",
              "  'Category:Metafictional works',\n",
              "  'Category:Nonlinear narrative films',\n",
              "  'Category:Performance capture in film',\n",
              "  'Category:Self-reflexive films',\n",
              "  'Category:Superhero comedy films',\n",
              "  'Category:Vigilante films',\n",
              "  'Category:X-Men films'],\n",
              " '84%',\n",
              " '6.9/10']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVoDTa1nWeJI",
        "colab_type": "code",
        "outputId": "97bdf5e9-cbdb-43f8-c53e-0e5bee6db68a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(movies)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N2TuPDmW9ei",
        "colab_type": "code",
        "outputId": "e6487fa3-5234-47c7-d92e-03ef1029dc1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "link_counts = Counter()\n",
        "for movie in movies:\n",
        "    link_counts.update(movie[2])\n",
        "link_counts.most_common(10)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Rotten Tomatoes', 9393),\n",
              " ('Category:English-language films', 5882),\n",
              " ('Category:American films', 5867),\n",
              " ('Variety (magazine)', 5450),\n",
              " ('Metacritic', 5112),\n",
              " ('Box Office Mojo', 4186),\n",
              " ('The New York Times', 3818),\n",
              " ('The Hollywood Reporter', 3553),\n",
              " ('Roger Ebert', 2707),\n",
              " ('Los Angeles Times', 2454)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0ewbxfGYs-A",
        "colab_type": "code",
        "outputId": "eef278dd-6631-4f84-d9e9-f0d8c941bd7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "top_links = [link for link, c in link_counts.items() if c >= 3]\n",
        "link_to_idx = {link: idx for idx, link in enumerate(top_links)}\n",
        "movie_to_idx = {movie[0]: idx for idx, movie in enumerate(movies)}\n",
        "pairs = []\n",
        "for movie in movies:\n",
        "    pairs.extend((link_to_idx[link], movie_to_idx[movie[0]]) \n",
        "                 for link in movie[2] if link in link_to_idx)\n",
        "pairs_set = set(pairs)\n",
        "len(pairs), len(top_links), len(movie_to_idx)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(949544, 66913, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TlfxEo0bZaF",
        "colab_type": "code",
        "outputId": "58b5ad42-a121-4761-b75c-3afa67e696af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "def movie_embedding_model(embedding_size=50):\n",
        "    link = Input(name=\"link\", shape=(1,))\n",
        "    movie = Input(name=\"movie\", shape=(1,))\n",
        "    link_embedding = Embedding(name=\"link_enbedding\", input_dim=len(top_links),\n",
        "                               output_dim=embedding_size)(link)\n",
        "    movie_embedding = Embedding(name=\"movie_enbedding\", input_dim=len(movie_to_idx),\n",
        "                               output_dim=embedding_size)(movie)\n",
        "    dot = Dot(name=\"dot_product\", normalize=True, \n",
        "              axes=2)([link_embedding, movie_embedding])\n",
        "    merged = Reshape((1, ))(dot)\n",
        "    model = Model(inputs=[link, movie], outputs=[merged])\n",
        "    model.compile(optimizer=\"nadam\", loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "model = movie_embedding_model()\n",
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "link (InputLayer)               (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "movie (InputLayer)              (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "link_enbedding (Embedding)      (None, 1, 50)        3345650     link[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "movie_enbedding (Embedding)     (None, 1, 50)        500000      movie[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dot_product (Dot)               (None, 1, 1)         0           link_enbedding[0][0]             \n",
            "                                                                 movie_enbedding[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 1)            0           dot_product[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 3,845,650\n",
            "Trainable params: 3,845,650\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NKPwrj_f_No",
        "colab_type": "code",
        "outputId": "2f300c58-fce4-42bd-ecdf-dbe6bf2b485e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "random.seed(5)\n",
        "\n",
        "def batchifier(pairs, positive_samples=50, negative_ratio=10):\n",
        "    batch_size = positive_samples * (1 + negative_ratio)\n",
        "    batch = np.zeros((batch_size, 3))\n",
        "    while True:\n",
        "        for idx, (link_id, movie_id) in enumerate(random.sample(pairs, positive_samples)):\n",
        "            batch[idx, :] = (link_id, movie_id, 1)\n",
        "        while idx < batch_size:\n",
        "            movie_id = random.randrange(len(movie_to_idx))\n",
        "            link_id = random.randrange(len(top_links))\n",
        "            if not (link_id, movie_id) in pairs_set:\n",
        "                batch[idx, :] = (link_id, movie_id, -1)\n",
        "                idx += 1\n",
        "        np.random.shuffle(batch)\n",
        "        yield {\"link\": batch[:, 0], \"movie\": batch[:, 1]}, batch[:, 2]\n",
        "next(batchifier(pairs, positive_samples=3, negative_ratio=2))            "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'link': array([31254., 32680., 32643., 32318., 13365., 48731., 20558., 22418.,\n",
              "          3801.]),\n",
              "  'movie': array([5530., 9403., 7628., 7685., 6238., 1854.,  849., 1529., 5874.])},\n",
              " array([ 1., -1., -1., -1., -1., -1., -1.,  1., -1.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbpFWThuo0KL",
        "colab_type": "code",
        "outputId": "ad60ea29-ee7f-48c8-83e7-95d4e8538348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "positive_samples_per_batch = 512\n",
        "\n",
        "model.fit_generator(batchifier(pairs, \n",
        "                               positive_samples=positive_samples_per_batch, \n",
        "                               negative_ratio=10),\n",
        "                    epochs=15, \n",
        "                    steps_per_epoch=len(pairs) // positive_samples_per_batch,\n",
        "                    verbose=2)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            " - 54s - loss: 0.3886\n",
            "Epoch 2/15\n",
            " - 53s - loss: 0.2417\n",
            "Epoch 3/15\n",
            " - 53s - loss: 0.2357\n",
            "Epoch 4/15\n",
            " - 53s - loss: 0.2336\n",
            "Epoch 5/15\n",
            " - 53s - loss: 0.2323\n",
            "Epoch 6/15\n",
            " - 53s - loss: 0.2310\n",
            "Epoch 7/15\n",
            " - 54s - loss: 0.2319\n",
            "Epoch 8/15\n",
            " - 54s - loss: 0.2304\n",
            "Epoch 9/15\n",
            " - 54s - loss: 0.2297\n",
            "Epoch 10/15\n",
            " - 53s - loss: 0.2277\n",
            "Epoch 11/15\n",
            " - 53s - loss: 0.2286\n",
            "Epoch 12/15\n",
            " - 53s - loss: 0.2283\n",
            "Epoch 13/15\n",
            " - 54s - loss: 0.2295\n",
            "Epoch 14/15\n",
            " - 53s - loss: 0.2278\n",
            "Epoch 15/15\n",
            " - 54s - loss: 0.2288\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f66f5e836a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuggoDR-rwHu",
        "colab_type": "code",
        "outputId": "3377b30b-c00d-4b58-d588-1181e782a2be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "movie = model.get_layer(\"movie_enbedding\")\n",
        "movie_weights = movie.get_weights()[0]\n",
        "movie_lengths = np.linalg.norm(movie_weights, axis=1)\n",
        "normalized_movies = (movie_weights.T / movie_lengths).T\n",
        "\n",
        "def similar_movies(movie):\n",
        "    dists = np.dot(normalized_movies, normalized_movies[movie_to_idx[movie]])\n",
        "    closet = np.argsort(dists)[-10:]\n",
        "    for c in reversed(closet):\n",
        "        print(c, movies[c][0], dists[c])\n",
        "        \n",
        "similar_movies('Rogue One')        "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29 Rogue One 1.0000001\n",
            "101 Prometheus (2012 film) 0.97176385\n",
            "3349 Star Wars: The Force Awakens 0.9674347\n",
            "19 Interstellar (film) 0.9650758\n",
            "181 Pacific Rim (film) 0.95642644\n",
            "22 Jurassic World 0.9562415\n",
            "160 Jupiter Ascending 0.95237947\n",
            "245 Gravity (film) 0.9506657\n",
            "169 Alice in Wonderland (2010 film) 0.9504535\n",
            "34 Doctor Strange (film) 0.9497459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjKLRtgNwDpt",
        "colab_type": "code",
        "outputId": "39bdf2c9-5666-4ff7-efc2-07eb66f3fdcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "movie_weights.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZl2RqDtwTay",
        "colab_type": "code",
        "outputId": "a9cc37e6-f8c8-4093-cda2-eb8e36498a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "movie_weights[0].shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6NCV0Pe7fy-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "a9d074bf-59e9-4acf-e2da-cb6bb8044333"
      },
      "source": [
        "link = model.get_layer('link_enbedding')\n",
        "link_weights = link.get_weights()[0]\n",
        "link_lengths = np.linalg.norm(link_weights, axis=1)\n",
        "normalized_links = (link_weights.T / link_lengths).T\n",
        "\n",
        "def similar_links(link):\n",
        "    dists = np.dot(normalized_links, normalized_links[link_to_idx[link]])\n",
        "    closest = np.argsort(dists)[-10:]\n",
        "    for c in reversed(closest):\n",
        "        print(c, top_links[c], dists[c])\n",
        "\n",
        "similar_links('George Lucas')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127 George Lucas 1.0000001\n",
            "3176 Star Wars (film) 0.9450498\n",
            "976 Hugo Award for Best Dramatic Presentation 0.93502736\n",
            "4830 widescreen 0.9331149\n",
            "2707 Star Wars 0.9302409\n",
            "2778 Lucasfilm 0.92021817\n",
            "3203 home video 0.92018425\n",
            "1671 dailies 0.91508174\n",
            "2721 Jaws (film) 0.9053166\n",
            "3040 Simon & Schuster 0.90185064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkZPgTTq7g7D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5babf215-8b3f-46fd-8a66-cdd65cf015d0"
      },
      "source": [
        "best = ['Star Wars: The Force Awakens', 'The Martian (film)', 'Tangerine (film)', 'Straight Outta Compton (film)',\n",
        "        'Brooklyn (film)', 'Carol (film)', 'Spotlight (film)']\n",
        "worst = ['American Ultra', 'The Cobbler (2014 film)', 'Entourage (film)', 'Fantastic Four (2015 film)',\n",
        "         'Get Hard', 'Hot Pursuit (2015 film)', 'Mortdecai (film)', 'Serena (2014 film)', 'Vacation (2015 film)']\n",
        "y = np.asarray([1 for _ in best] + [0 for _ in worst])\n",
        "X = np.asarray([normalized_movies[movie_to_idx[movie]] for movie in best + worst])\n",
        "X.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcvCRGaz9i9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "50fdfbbc-ca0a-4449-bbfb-8d73f8439ea7"
      },
      "source": [
        "clf = svm.SVC(kernel=\"linear\")\n",
        "clf.fit(X, y)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
              "    shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2bIIZ6R9wFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "d379fcb2-e004-4b80-afd1-d6fb3b66a490"
      },
      "source": [
        "estimated_movie_ratings = clf.decision_function(normalized_movies)\n",
        "best = np.argsort(estimated_movie_ratings)\n",
        "print('best:')\n",
        "for c in reversed(best[-5:]):\n",
        "    print(c, movies[c][0], estimated_movie_ratings[c])\n",
        "\n",
        "print('worst:')\n",
        "for c in best[:5]:\n",
        "    print(c, movies[c][0], estimated_movie_ratings[c])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best:\n",
            "70 Carol (film) 0.9999062031306364\n",
            "307 Les Misérables (2012 film) 0.9963343321734829\n",
            "481 The Devil Wears Prada (film) 0.9421521218876757\n",
            "458 Hugo (film) 0.9345344633094338\n",
            "66 Skyfall 0.9310475594488188\n",
            "worst:\n",
            "9890 Beach Party -1.5444213490393652\n",
            "4100 See No Evil (2006 film) -1.5398974410194204\n",
            "9595 Speed Zone -1.5246068130600527\n",
            "4487 Tremors (franchise) -1.5145273638105368\n",
            "7593 Trojan War (film) -1.4950135907038253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOAGi96bBx2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rotten_y = np.asarray([float(movie[-2][:-1])/100\n",
        "                       for movie in  movies if movie[-2]])\n",
        "rotten_X = np.asarray([normalized_movies[movie_to_idx[movie[0]]]\n",
        "                       for movie in movies if movie[-2]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXwng-ztDDJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "60f6fba1-4950-4cb0-c65d-1bce65c07b4e"
      },
      "source": [
        "TRAINING_CUT_OFF = int(len(rotten_X) * 0.8)\n",
        "regr = LinearRegression()\n",
        "regr.fit(rotten_X[:TRAINING_CUT_OFF], rotten_y[:TRAINING_CUT_OFF])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTwdkZBrDWGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0d1f7644-cb47-49a9-fcdf-3d90483100b3"
      },
      "source": [
        "error = (regr.predict(rotten_X[TRAINING_CUT_OFF:]) - rotten_y[TRAINING_CUT_OFF:])\n",
        "'mean square error %2.2f' % np.mean(error ** 2)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mean square error 0.06'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlXbLs2dDVcl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6314fa8e-4f81-4f92-9a41-1d43b250d370"
      },
      "source": [
        "error = (np.mean(rotten_y[:TRAINING_CUT_OFF]) - rotten_y[TRAINING_CUT_OFF:])\n",
        "'mean square error %2.2f' % np.mean(error ** 2)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mean square error 0.09'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ2JbyNzDdR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "9edfbb0f-e568-4a96-d267-23968bbfb05c"
      },
      "source": [
        "def gross(movie):\n",
        "    v = movie[1].get('gross')\n",
        "    if not v or not ' ' in v:\n",
        "        return None\n",
        "    v, unit = v.split(' ', 1)\n",
        "    unit = unit.lower()\n",
        "    if not unit in ('million', 'billion'):\n",
        "        return None\n",
        "    if not v.startswith('$'):\n",
        "        return None\n",
        "    try:\n",
        "        v = float(v[1:])\n",
        "    except ValueError:\n",
        "        return None\n",
        "    if unit == 'billion':\n",
        "        v *= 1000\n",
        "    return v\n",
        "\n",
        "movie_gross = [gross(m) for m in movies]\n",
        "movie_gross = np.asarray([gr for gr in movie_gross if gr is not None])\n",
        "highest = np.argsort(movie_gross)[-10:]\n",
        "for c in reversed(highest):\n",
        "    print(c, movies[c][0], movie_gross[c])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6 The Martian (film) 10900.0\n",
            "7 List of Marvel Cinematic Universe films 4300.0\n",
            "49 Back to the Future 3900.0\n",
            "71 The Conjuring 2932.0\n",
            "162 Thor (film) 2464.0\n",
            "36 Furious 7 2340.0\n",
            "30 Finding Dory 2187.0\n",
            "1906 Jane Eyre (2011 film) 2068.0\n",
            "19 Interstellar (film) 1670.0\n",
            "2251 An American Werewolf in London 1655.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MThHRqapEwJf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b67aa210-c99a-4851-a6df-f52fbd7267e6"
      },
      "source": [
        "gross_y = np.asarray([gr for gr in movie_gross if gr])\n",
        "gross_X = np.asarray([normalized_movies[movie_to_idx[movie[0]]] for movie, gr in zip(movies, movie_gross) if gr])\n",
        "\n",
        "TRAINING_CUT_OFF = int(len(gross_X) * 0.8)\n",
        "regr = LinearRegression()\n",
        "regr.fit(gross_X[:TRAINING_CUT_OFF], gross_y[:TRAINING_CUT_OFF])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2ZceFwRE-Vh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc63af24-3f9b-4545-9aaa-8885819319fa"
      },
      "source": [
        "error = (regr.predict(gross_X[TRAINING_CUT_OFF:]) - gross_y[TRAINING_CUT_OFF:])\n",
        "'mean square error %2.2f' % np.mean(error ** 2)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mean square error 8336.13'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGelqnOfFBHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ec7de039-ca4c-4fd1-ce0c-d11a3eb033d5"
      },
      "source": [
        "error = (np.mean(gross_y[:TRAINING_CUT_OFF]) - gross_y[TRAINING_CUT_OFF:])\n",
        "'mean square error %2.2f' % np.mean(error ** 2)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mean square error 14115.59'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    }
  ]
}
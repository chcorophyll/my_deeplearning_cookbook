{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_Generating Text in the Style of an Example Text.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chcorophyll/my_deeplearning_cookbook/blob/master/my_Generating_Text_in_the_Style_of_an_Example_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj_kRB3DSHGQ",
        "colab_type": "code",
        "outputId": "46c9ba2c-d24b-4412-f90d-27b3f6e6b985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!git clone https://github.com/chcorophyll/deep_learning_cookbook.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep_learning_cookbook'...\n",
            "remote: Enumerating objects: 427, done.\u001b[K\n",
            "remote: Total 427 (delta 0), reused 0 (delta 0), pack-reused 427\u001b[K\n",
            "Receiving objects: 100% (427/427), 160.26 MiB | 34.73 MiB/s, done.\n",
            "Resolving deltas: 100% (207/207), done.\n",
            "Checking out files: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNesQf5FSiM1",
        "colab_type": "code",
        "outputId": "b5d34216-2746-4e1c-fbf3-2c9ac8abf79b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deep_learning_cookbook\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhYn9hGOSbOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "path_org = os.getcwd()\n",
        "data_path = os.path.join(path_org, \"deep_learning_cookbook\")\n",
        "os.chdir(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGwhDwYncFTO",
        "colab_type": "code",
        "outputId": "7b2ef170-ef7c-40e3-92d1-85c34d6337da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/deep_learning_cookbook'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afz0jFRTcPVq",
        "colab_type": "code",
        "outputId": "f05baa87-987c-4441-bd98-6dcd3ac73d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'03.1 Using pre trained word embeddings.ipynb'\n",
            "'03.2 Domain specific ranking using word2vec cosine distance.ipynb'\n",
            "'04.1 Collect movie data from Wikipedia.ipynb'\n",
            "'04.2 Build a recommender system based on outgoing Wikipedia links.ipynb'\n",
            "'05.1 Generating Text in the Style of an Example Text.ipynb'\n",
            "'06.1 Question matching.ipynb'\n",
            "'07.1 Text Classification.ipynb'\n",
            "'07.2 Emoji Suggestions.ipynb'\n",
            "'07.3 Tweet Embeddings.ipynb'\n",
            "'08.1 Sequence to sequence mapping.ipynb'\n",
            "'08.2 Import Gutenberg.ipynb'\n",
            "'08.3 Subword tokenizing.ipynb'\n",
            "'09.1 Reusing a pretrained image recognition network.ipynb'\n",
            "'09.2 Images as embeddings.ipynb'\n",
            "'09.3 Retraining.ipynb'\n",
            "'10.1 Building an inverse image search service.ipynb'\n",
            "'11.1 Detecting Multiple Images.ipynb'\n",
            "'12.1 Activation Optimization.ipynb'\n",
            "'12.2 Neural Style.ipynb'\n",
            "'13.1 Quick Draw Cat Autoencoder.ipynb'\n",
            "'13.2 Variational Autoencoder.ipynb'\n",
            "'13.5 Quick Draw Autoencoder.ipynb'\n",
            "'14.1 Importing icons.ipynb'\n",
            "'14.2 Icon Autoencoding.ipynb'\n",
            "'14.2 Variational Autoencoder Icons.ipynb'\n",
            "'14.3 Icon GAN.ipynb'\n",
            "'14.4 Icon RNN.ipynb'\n",
            "'15.1 Song Classification.ipynb'\n",
            "'15.2 Index Local MP3s.ipynb'\n",
            "'15.3 Spotify Playlists.ipynb'\n",
            "'15.4 Train a music recommender.ipynb'\n",
            "'16.1 Productionize Embeddings.ipynb'\n",
            "'16.2 Prepare Keras model for Tensorflow Serving.ipynb'\n",
            "'16.3 Prepare model for iOS.ipynb'\n",
            "'16.4 Simple Text Generation.ipynb'\n",
            " data\n",
            " export_keras_to_tensor_flow_serving.py\n",
            " keras_js\n",
            " keras_server.py\n",
            " LICENSE\n",
            " nb_utils.py\n",
            " README.md\n",
            " requirements.in\n",
            " requirements.txt\n",
            " seq2seq_server.py\n",
            "'Simple Seq2Seq.ipynb'\n",
            " simple_server.py\n",
            " style_transfer\n",
            " zoo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVo5QVcPaLBz",
        "colab_type": "code",
        "outputId": "5c3b9af0-6265-4990-903a-4cf1da67cc88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!sudo apt-get install libdb++-dev\n",
        "!export BERKELEYDB_DIR=/usr\n",
        "!pip install gutenberg"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libdb5.3 libdb5.3++ libdb5.3++-dev libdb5.3-dev\n",
            "Suggested packages:\n",
            "  db5.3-doc\n",
            "The following NEW packages will be installed:\n",
            "  libdb++-dev libdb5.3++ libdb5.3++-dev libdb5.3-dev\n",
            "The following packages will be upgraded:\n",
            "  libdb5.3\n",
            "1 upgraded, 4 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 2,918 kB of archives.\n",
            "After this operation, 8,395 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdb5.3 amd64 5.3.28-13.1ubuntu1.1 [672 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdb5.3++ amd64 5.3.28-13.1ubuntu1.1 [703 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdb5.3-dev amd64 5.3.28-13.1ubuntu1.1 [762 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdb5.3++-dev amd64 5.3.28-13.1ubuntu1.1 [778 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdb++-dev amd64 1:5.3.21~exp1ubuntu2 [2,340 B]\n",
            "Fetched 2,918 kB in 1s (1,964 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 130942 files and directories currently installed.)\n",
            "Preparing to unpack .../libdb5.3_5.3.28-13.1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libdb5.3:amd64 (5.3.28-13.1ubuntu1.1) over (5.3.28-13.1ubuntu1) ...\n",
            "Setting up libdb5.3:amd64 (5.3.28-13.1ubuntu1.1) ...\n",
            "Selecting previously unselected package libdb5.3++:amd64.\n",
            "(Reading database ... 130942 files and directories currently installed.)\n",
            "Preparing to unpack .../libdb5.3++_5.3.28-13.1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libdb5.3++:amd64 (5.3.28-13.1ubuntu1.1) ...\n",
            "Selecting previously unselected package libdb5.3-dev.\n",
            "Preparing to unpack .../libdb5.3-dev_5.3.28-13.1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libdb5.3-dev (5.3.28-13.1ubuntu1.1) ...\n",
            "Selecting previously unselected package libdb5.3++-dev.\n",
            "Preparing to unpack .../libdb5.3++-dev_5.3.28-13.1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libdb5.3++-dev (5.3.28-13.1ubuntu1.1) ...\n",
            "Selecting previously unselected package libdb++-dev:amd64.\n",
            "Preparing to unpack .../libdb++-dev_1%3a5.3.21~exp1ubuntu2_amd64.deb ...\n",
            "Unpacking libdb++-dev:amd64 (1:5.3.21~exp1ubuntu2) ...\n",
            "Setting up libdb5.3-dev (5.3.28-13.1ubuntu1.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libdb5.3++:amd64 (5.3.28-13.1ubuntu1.1) ...\n",
            "Setting up libdb5.3++-dev (5.3.28-13.1ubuntu1.1) ...\n",
            "Setting up libdb++-dev:amd64 (1:5.3.21~exp1ubuntu2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Collecting gutenberg\n",
            "  Downloading https://files.pythonhosted.org/packages/14/b1/6e99867c38e70d46366966a0a861c580377f38312cf9dbad38b82ed1823d/Gutenberg-0.7.0.tar.gz\n",
            "Collecting bsddb3>=6.1.0 (from gutenberg)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/fc/ebfbd4de236b493f9ece156f816c21df0ae87ccc22604c5f9b664efef1b9/bsddb3-6.2.6.tar.gz (239kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (0.16.0)\n",
            "Collecting rdflib-sqlalchemy>=0.3.8 (from gutenberg)\n",
            "  Downloading https://files.pythonhosted.org/packages/92/a2/bc580a51ac1f9680aa04da4b6e96d499903d6e606d2f78f02e73527799da/rdflib_sqlalchemy-0.3.8-py3-none-any.whl\n",
            "Collecting rdflib>=4.2.0 (from gutenberg)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fe/630bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdflib-4.2.2-py3-none-any.whl (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 52.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.5.1 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (2.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (41.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (1.12.0)\n",
            "Collecting alembic>=0.8.8 (from rdflib-sqlalchemy>=0.3.8->gutenberg)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/8b/fa3bd058cccd5e9177fea4efa26bfb769228fdd3178436ad5e05830ef6ef/alembic-1.0.10.tar.gz (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 28.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy>=1.1.4 in /usr/local/lib/python3.6/dist-packages (from rdflib-sqlalchemy>=0.3.8->gutenberg) (1.3.4)\n",
            "Collecting isodate (from rdflib>=4.2.0->gutenberg)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 25.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib>=4.2.0->gutenberg) (2.4.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (3.0.4)\n",
            "Collecting Mako (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/af/a6d8aa7b8909a36074f517b15222e3a2fbd5ef3452c0a686e3d43043dd3b/Mako-1.0.12.tar.gz (460kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 50.9MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3 (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg)\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (2.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (1.1.1)\n",
            "Building wheels for collected packages: gutenberg, bsddb3, alembic, Mako\n",
            "  Building wheel for gutenberg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/cd/75/4bc6f16541a1b7a69b02168da567695b2271c23ac4a0a0a453\n",
            "  Building wheel for bsddb3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/b8/b3/fa84db10bf8c563e4ba1a72837a0946d123f12adb34b164bf5\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/cf/b3/0eb5c89ea6aa1b49cb41315f9ec139ada8cbffd575bf170d43\n",
            "  Building wheel for Mako (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/7b/ae/5addd138cd8175503b9782737bada30d0c88310d08c106f9bf\n",
            "Successfully built gutenberg bsddb3 alembic Mako\n",
            "Installing collected packages: bsddb3, Mako, python-editor, alembic, isodate, rdflib, rdflib-sqlalchemy, gutenberg\n",
            "Successfully installed Mako-1.0.12 alembic-1.0.10 bsddb3-6.2.6 gutenberg-0.7.0 isodate-0.6.0 python-editor-1.0.4 rdflib-4.2.2 rdflib-sqlalchemy-0.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Geb_lfAWmn",
        "colab_type": "code",
        "outputId": "729e7281-c2e7-4f09-a210-4fe22b411124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "!pip install gutenberg"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gutenberg in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (1.12.0)\n",
            "Requirement already satisfied: bsddb3>=6.1.0 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (6.2.6)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (0.16.0)\n",
            "Requirement already satisfied: rdflib-sqlalchemy>=0.3.8 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (0.3.8)\n",
            "Requirement already satisfied: rdflib>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.5.1 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (2.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (41.0.1)\n",
            "Requirement already satisfied: alembic>=0.8.8 in /usr/local/lib/python3.6/dist-packages (from rdflib-sqlalchemy>=0.3.8->gutenberg) (1.0.10)\n",
            "Requirement already satisfied: SQLAlchemy>=1.1.4 in /usr/local/lib/python3.6/dist-packages (from rdflib-sqlalchemy>=0.3.8->gutenberg) (1.3.4)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.6/dist-packages (from rdflib>=4.2.0->gutenberg) (0.6.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib>=4.2.0->gutenberg) (2.4.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (2.5.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (1.0.12)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (1.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_ARJ3QVS1oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    GUTENBERG = True\n",
        "    from gutenberg.acquire import load_etext\n",
        "    from gutenberg.query import get_etexts, get_metadata\n",
        "    from gutenberg.acquire import get_metadata_cache\n",
        "    from gutenberg.acquire.text import UnknownDownloadUriException\n",
        "    from gutenberg.cleanup import strip_headers\n",
        "    from gutenberg._domain_model.exceptions import CacheAlreadyExistsException\n",
        "except ImportError:\n",
        "    GUTENBERG = False\n",
        "    print('Gutenberg is not installed. See instructions at https://pypi.python.org/pypi/Gutenberg')\n",
        "from keras.models import Input, Model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "import keras.callbacks\n",
        "import keras.backend as K\n",
        "import scipy.misc\n",
        "import json\n",
        "\n",
        "import os, sys\n",
        "import re\n",
        "import PIL\n",
        "from PIL import ImageDraw\n",
        "\n",
        "from keras.optimizers import RMSprop\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.utils import get_file\n",
        "\n",
        "from IPython.display import clear_output, Image, display, HTML\n",
        "try:\n",
        "    from io import BytesIO\n",
        "except ImportError:\n",
        "    from StringIO import StringIO as BytesIO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6tu3wjgY3O3",
        "colab_type": "code",
        "outputId": "00be6822-4773-4e4c-aa90-aa61741f091b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        }
      },
      "source": [
        "if GUTENBERG:\n",
        "    cache = get_metadata_cache()\n",
        "    try:\n",
        "        cache.populate()\n",
        "    except CacheAlreadyExistsException:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rdflib/namespace.py\u001b[0m in \u001b[0;36mterm\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mURIRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s_%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'datatype'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9dd7c4934ee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metadata_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mCacheAlreadyExistsException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gutenberg/acquire/metadata.py\u001b[0m in \u001b[0;36mpopulate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_metadata_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetadata_archive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mfact\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_metadata_triples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_archive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gutenberg/acquire/metadata.py\u001b[0m in \u001b[0;36m_iter_metadata_triples\u001b[0;34m(cls, metadata_archive_path)\u001b[0m\n\u001b[1;32m    166\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mdisable_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                         \u001b[0mextracted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata_archive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mfact\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_is_invalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rdflib/graph.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, publicID, format, location, file, data, **args)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rdflib/plugins/parsers/rdfxml.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, sink, **args)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;31m# content_handler.reset()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;31m# self._parser.reset()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.6/xml/sax/expatreader.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cont_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetDocumentLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExpatLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mxmlreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementalParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;31m# bpo-30264: Close the source on error to not leak resources:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/xml/sax/xmlreader.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/xml/sax/expatreader.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data, isFinal)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# document. When feeding chunks, they are not normally final -\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;31m# except when invoked from close.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misFinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexpat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAXParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mErrorString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m../Modules/pyexpat.c\u001b[0m in \u001b[0;36mStartElement\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/xml/sax/expatreader.py\u001b[0m in \u001b[0;36mstart_element_ns\u001b[0;34m(self, name, attrs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         self._cont_handler.startElementNS(pair, None,\n\u001b[0;32m--> 370\u001b[0;31m                                           AttributesNSImpl(newattrs, qnames))\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mend_element_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rdflib/plugins/parsers/rdfxml.py\u001b[0m in \u001b[0;36mstartElementNS\u001b[0;34m(self, name, qname, attrs)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mlanguage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mendElementNS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rdflib/plugins/parsers/rdfxml.py\u001b[0m in \u001b[0;36mproperty_element_start\u001b[0;34m(self, name, qname, attrs)\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0mnext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_element_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mdatatype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0mlanguage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdatatype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rdflib/namespace.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rdflib/namespace.py\u001b[0m in \u001b[0;36mterm\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mURIRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s_%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0u2et8Q-6ak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if GUTENBERG:\n",
        "    for text_id in get_etexts(\"author\", \"Shakespeare, William\"):\n",
        "        print(text_id, list(get_metadata(\"title\", text_id))[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP_0TPtvAJ9_",
        "colab_type": "code",
        "outputId": "4b668c8d-674b-4394-ad66-1476393bc013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "if GUTENBERG:\n",
        "    shakespeare = strip_headers(load_etext(100))\n",
        "else:\n",
        "    path = get_file('shakespeare', 'https://storage.googleapis.com/deep-learning-cookbook/100-0.txt')\n",
        "    shakespeare = open(path).read()\n",
        "training_text = shakespeare.split('\\nTHE END', 1)[-1]\n",
        "len(training_text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5466234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QDHxh4RF-K6",
        "colab_type": "code",
        "outputId": "e029c30b-570a-4a6e-fb31-c080ff5eb702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "chars = list(sorted(set(training_text)))\n",
        "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
        "len(chars)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpUXgP6aGjPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def char_rnn_model(num_chars, num_layers, num_nodes=512, dropout=0.1):\n",
        "    input = Input(shape=(None, num_chars), name=\"input\")\n",
        "    prev = input\n",
        "    for i in range(num_layers):\n",
        "        lstm = LSTM(num_nodes, return_sequences=True, name=\"lstm_layer_%d\" %(i + 1))(prev)\n",
        "        if dropout:\n",
        "            prev = Dropout(dropout)(lstm)\n",
        "        else:\n",
        "            prev = lstm\n",
        "    dense = TimeDistributed(Dense(num_chars, name=\"dense\", activation=\"softmax\"))(prev)\n",
        "    model = Model(inputs=[input], outputs=[dense])\n",
        "    optimizer = RMSprop(lr=0.01)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hus5bl5fWN9E",
        "colab_type": "code",
        "outputId": "7544b605-d4cf-47e0-cd52-081bb9b158fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "model = char_rnn_model(len(chars), num_layers=2, num_nodes=640, dropout=0)\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0625 00:29:31.145601 139834438612864 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0625 00:29:31.187596 139834438612864 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0625 00:29:31.189401 139834438612864 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0625 00:29:34.001946 139834438612864 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0625 00:29:34.012756 139834438612864 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, None, 101)         0         \n",
            "_________________________________________________________________\n",
            "lstm_layer_1 (LSTM)          (None, None, 640)         1899520   \n",
            "_________________________________________________________________\n",
            "lstm_layer_2 (LSTM)          (None, None, 640)         3279360   \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, None, 101)         64741     \n",
            "=================================================================\n",
            "Total params: 5,243,621\n",
            "Trainable params: 5,243,621\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFlLIokSXXOE",
        "colab_type": "code",
        "outputId": "d9f5c792-df6b-4841-a481-16d0976d7cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "(101 * 640 + 640*640)*4 + 640*4 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1899520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyEZ6z7VbrYe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "534ef0ec-da07-4de0-86d4-c40779ccc426"
      },
      "source": [
        "CHUNK_SIZE = 160\n",
        "\n",
        "def data_generator(all_text, char_to_idx, batch_size, chunk_size):\n",
        "    X = np.zeros((batch_size, chunk_size, len(char_to_idx)))\n",
        "    y = np.zeros((batch_size, chunk_size, len(char_to_idx)))\n",
        "    while True:\n",
        "        for row in range(batch_size):\n",
        "            idx = random.randrange(len(all_text) - chunk_size - 1)\n",
        "            chunk = np.zeros((chunk_size + 1, len(char_to_idx)))\n",
        "            for i in range(chunk_size + 1):\n",
        "                chunk[i, char_to_idx[all_text[idx + i]]] = 1\n",
        "            X[row, :, :] = chunk[:chunk_size]\n",
        "            y[row, :, :] = chunk[1:]\n",
        "        yield X, y\n",
        "\n",
        "next(data_generator(training_text, char_to_idx, 4, chunk_size=CHUNK_SIZE))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]]),\n",
              " array([[[0., 0., 1., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqsOIH2qnuAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "7e820d84-7d36-48dc-8382-786151c2ef56"
      },
      "source": [
        "early = keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                              min_delta=0.03,\n",
        "                              patience=3,\n",
        "                              verbose=0, mode='auto')\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "model.fit_generator(\n",
        "    data_generator(training_text, char_to_idx, batch_size=BATCH_SIZE, chunk_size=CHUNK_SIZE),\n",
        "    epochs=40,\n",
        "    callbacks=[early,],\n",
        "    steps_per_epoch=2 * len(training_text) / (BATCH_SIZE * CHUNK_SIZE),\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0625 00:35:09.789474 139834438612864 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0625 00:35:11.030517 139834438612864 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            " - 179s - loss: 3.5777 - acc: 0.1605\n",
            "Epoch 2/40\n",
            " - 176s - loss: 3.3022 - acc: 0.1952\n",
            "Epoch 3/40\n",
            " - 177s - loss: 3.2754 - acc: 0.1971\n",
            "Epoch 4/40\n",
            " - 182s - loss: 2.9162 - acc: 0.2628\n",
            "Epoch 5/40\n",
            " - 185s - loss: 2.4996 - acc: 0.3863\n",
            "Epoch 6/40\n",
            " - 185s - loss: 2.4097 - acc: 0.4155\n",
            "Epoch 7/40\n",
            " - 185s - loss: 2.3806 - acc: 0.4245\n",
            "Epoch 8/40\n",
            " - 185s - loss: 2.3580 - acc: 0.4310\n",
            "Epoch 9/40\n",
            " - 184s - loss: 2.3470 - acc: 0.4351\n",
            "Epoch 10/40\n",
            " - 185s - loss: 2.3580 - acc: 0.4337\n",
            "Epoch 11/40\n",
            " - 184s - loss: 2.3123 - acc: 0.4449\n",
            "Epoch 12/40\n",
            " - 184s - loss: 2.3162 - acc: 0.4456\n",
            "Epoch 13/40\n",
            " - 184s - loss: 2.3426 - acc: 0.4393\n",
            "Epoch 14/40\n",
            " - 184s - loss: 2.2972 - acc: 0.4504\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2d72c1efd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MTotUTfpgCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('zoo/06/shakespeare.json', 'w') as fout:\n",
        "    json.dump({\n",
        "        'chars': ''.join(chars),\n",
        "        'char_to_idx': char_to_idx,\n",
        "        'chunk_size': CHUNK_SIZE,\n",
        "    }, fout)\n",
        "model.save('zoo/06/shakespeare.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNhHiBKYrDP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "7396f5ca-e52b-47b9-cdce-a8ea742da5ec"
      },
      "source": [
        "def generate_output(model, training_text, start_index=None, diversity=None, amount=400):\n",
        "    if start_index is None:\n",
        "        start_index = random.randint(0, len(training_text) - CHUNK_SIZE - 1)\n",
        "    generated = training_text[start_index: start_index + CHUNK_SIZE]\n",
        "    yield generated + '#'\n",
        "    for i in range(amount):\n",
        "        x = np.zeros((1, len(generated), len(chars)))\n",
        "        for t, char in enumerate(generated):\n",
        "            x[0, t, char_to_idx[char]] = 1.\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        \n",
        "        if diversity is None:\n",
        "            next_index = np.argmax(preds[len(generated) - 1])\n",
        "        else:\n",
        "            preds = np.asarray(preds[len(generated) - 1]).astype('float64')\n",
        "            preds = np.log(preds) / diversity\n",
        "            exp_preds = np.exp(preds)\n",
        "            preds = exp_preds / np.sum(exp_preds)\n",
        "            probas = np.random.multinomial(1, preds, 1)\n",
        "            next_index = np.argmax(probas)     \n",
        "        next_char = chars[next_index]\n",
        "        yield next_char\n",
        "\n",
        "        generated += next_char\n",
        "    return generated\n",
        "\n",
        "for ch in generate_output(model, training_text):\n",
        "    sys.stdout.write(ch)\n",
        "print()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " gilt copper\n",
            "       crown.\n",
            "    6. MARQUIS DORSET, bearing a sceptre of gold, on his head a\n",
            "       demi-coronal of gold. With him, the EARL OF SURREY,\n",
            "       bea#ring the King of                                                                                                                                                                                                                                                                                                                                                                                                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBLapUbxRh0H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "7c5745e8-7de4-4b9a-d9b7-acbb62f524a4"
      },
      "source": [
        "def generate_output(model, training_text, start_index=None, diversity=None, amount=400):\n",
        "    if start_index is None:\n",
        "        start_index = random.randint(0, len(training_text) - CHUNK_SIZE - 1)\n",
        "    fragment = training_text[start_index: start_index + CHUNK_SIZE]\n",
        "    generated = fragment\n",
        "    for i in range(amount):\n",
        "        x = np.zeros((1, CHUNK_SIZE, len(chars)))\n",
        "        for t, char in enumerate(fragment):\n",
        "            x[0, t, char_to_idx[char]] = 1.\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        preds = np.asarray(preds[len(fragment)-1])\n",
        "        next_index = np.argmax(preds)\n",
        "        next_char = chars[next_index]\n",
        "        generated += next_char\n",
        "        fragment = fragment[1:] + next_char\n",
        "    return generated\n",
        "        \n",
        "\n",
        "for line in generate_output(model, training_text).split(\"\\n\"):\n",
        "    print(line)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " traitor?\n",
            "    Sword, I will hallow thee for this thy deed\n",
            "    And hang thee o'er my tomb when I am dead.\n",
            "    Ne'er shall this blood be wiped from thy point,\n",
            "    The sea is born and strong and seen the state of this to thee.\n",
            "                                                                                                                                                                                                                                                                                                                                                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsgFQRgNNcCh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6dd312d-224a-4b61-bd99-ca4333444fa6"
      },
      "source": [
        "def find_python(rootdir):\n",
        "    matches = []\n",
        "    for root, dirnames, filenames in os.walk(rootdir):\n",
        "        for fn in filenames:\n",
        "            if fn.endswith('.py'):\n",
        "                matches.append(os.path.join(root, fn))\n",
        "\n",
        "    return matches\n",
        "#  + find_python(os.path.join(sys.executable.rsplit('/', 2)[0], 'lib'))\n",
        "srcs = find_python(random.__file__.rsplit('/', 1)[0])\n",
        "len(srcs)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK_tekM2PAKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# delete review\n",
        "# COMMENT_RE = re.compile(\"#.*\")\n",
        "# srcs = COMMENT_RE.sub(\" \", srcs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMtedd63P2Nb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42f0db98-2b2e-489d-dc7b-f4ad2a4a2793"
      },
      "source": [
        "def replacer(value):\n",
        "    value = \"\".join(ch for ch in value if ord(ch) < 127)\n",
        "    if not \" \" in value:\n",
        "        return value\n",
        "    if sum(1 for ch in value if ch.isalpha()) > 6:\n",
        "        return \"MSG\"\n",
        "    return value\n",
        "\n",
        "def replace_literals(st):\n",
        "    res = []\n",
        "    start_text = start_quote = i = 0\n",
        "    quote = ''\n",
        "    while i < len(st):\n",
        "        if quote:\n",
        "            if st[i: i + len(quote)] == quote:\n",
        "                quote = ''\n",
        "                start_text = i\n",
        "                res.append(replacer(st[start_quote: i]))\n",
        "        elif st[i] in '\"\\'':\n",
        "            quote = st[i]\n",
        "            if i < len(st) - 2 and st[i + 1] == st[i + 2] == quote:\n",
        "                quote = 3 * quote\n",
        "            start_quote = i + len(quote)\n",
        "            res.append(st[start_text: start_quote])\n",
        "        if st[i] == '\\n' and len(quote) == 1:\n",
        "            start_text = i\n",
        "            res.append(quote)\n",
        "            quote = ''\n",
        "        if st[i] == '\\\\':\n",
        "            i += 1\n",
        "        i += 1\n",
        "    return ''.join(res) + st[start_text:]\n",
        "\n",
        "#replace_literals('print(\"hel\\\\\"lo\")') + replace_literals(\"print('hel\\\\'lo world')\")\n",
        "replace_literals('this = \"wrong\\n')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this = \"\"\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lcBBp2qSVsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1029fff7-2729-4ad0-d322-b8fcd1fb42fe"
      },
      "source": [
        "COMMENT_RE = re.compile('#.*')\n",
        "python_code = []\n",
        "for fn in srcs:\n",
        "    try:\n",
        "        with open(fn, 'r') as fin:\n",
        "            src = fin.read()\n",
        "    except UnicodeDecodeError:\n",
        "        print('Could not read %s' % fn)\n",
        "    src = replace_literals(src)\n",
        "    src = COMMENT_RE.sub('', src)\n",
        "    python_code.append(src)\n",
        "\n",
        "python_code = '\\n\\n\\n'.join(python_code)\n",
        "len(python_code)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6332828"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDgY32zMTdyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5dc06686-f121-4561-b138-926f085d4e3a"
      },
      "source": [
        "py_chars = list(sorted(set(python_code)))\n",
        "py_char_to_idx = {ch: idx for idx, ch in enumerate(py_chars)}\n",
        "len(py_chars)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqD2ktftTqpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "b70ecc78-caca-4538-e3aa-8bfae38a2448"
      },
      "source": [
        "py_model = char_rnn_model(len(py_chars), num_layers=2, num_nodes=640, dropout=0)\n",
        "py_model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, None, 97)          0         \n",
            "_________________________________________________________________\n",
            "lstm_layer_1 (LSTM)          (None, None, 640)         1889280   \n",
            "_________________________________________________________________\n",
            "lstm_layer_2 (LSTM)          (None, None, 640)         3279360   \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, None, 97)          62177     \n",
            "=================================================================\n",
            "Total params: 5,230,817\n",
            "Trainable params: 5,230,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ntJl1drTtkx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "8d6037da-a10c-442e-ae6b-4e1ebc527fff"
      },
      "source": [
        "early = keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                              min_delta=0.03,\n",
        "                              patience=3,\n",
        "                              verbose=0, mode='auto')\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "py_model.fit_generator(\n",
        "    data_generator(python_code, py_char_to_idx, batch_size=BATCH_SIZE, chunk_size=160),\n",
        "    epochs=40,\n",
        "    callbacks=[early,],\n",
        "    steps_per_epoch=2 * len(python_code) / (BATCH_SIZE * 160),\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            " - 203s - loss: 3.1561 - acc: 0.3511\n",
            "Epoch 2/40\n",
            " - 209s - loss: 2.9980 - acc: 0.3578\n",
            "Epoch 3/40\n",
            " - 207s - loss: 3.0062 - acc: 0.3552\n",
            "Epoch 4/40\n",
            " - 207s - loss: 3.0315 - acc: 0.3555\n",
            "Epoch 5/40\n",
            " - 207s - loss: 3.0135 - acc: 0.3572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2d6efc3fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN9RdwMGWFXL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c3f07e7-2f05-4cd8-8b30-6cd59416be94"
      },
      "source": [
        "def generate_code(model, start_with='\\ndef ', end_with='\\n\\n', diversity=1.0):\n",
        "    generated = start_with\n",
        "    yield generated\n",
        "    for i in range(2000):\n",
        "        x = np.zeros((1, len(generated), len(py_chars)))\n",
        "        for t, char in enumerate(generated):\n",
        "            x[0, t, py_char_to_idx[char]] = 1.\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        \n",
        "        preds = np.asarray(preds[len(generated) - 1]).astype('float64')\n",
        "        preds = np.log(preds) / diversity\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "        probas = np.random.multinomial(1, preds, 1)\n",
        "        next_index = np.argmax(probas)        \n",
        "        next_char = py_chars[next_index]\n",
        "        yield next_char\n",
        "\n",
        "        generated += next_char\n",
        "        if generated.endswith(end_with):\n",
        "            break\n",
        "\n",
        "for i in range(20):\n",
        "    for ch in generate_code(py_model):\n",
        "        sys.stdout.write(ch)\n",
        "#         st += ch\n",
        "    print()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "def \n",
            "Ue\"x S.e Hre _S )t  e Nlioesae=i na, r o ye i. tf\"mp  tnnpt \n",
            " _  ' d\" (u l ait sN\"oti\n",
            "r +eeiwe iek tis   ofn(srs\n",
            "oc ar_e,tn\n",
            " _ t  _ \"tlb_ rf etie ioe\n",
            " r)'= dnes:-it \n",
            "   fue=ld_ omebm+c(\n",
            " r\"err Fl + x0e t nt=n 2 \n",
            " _b ca_S ctUeeol. fs   drf< nr   l snsr ,c_ni0e_Tm a\n",
            "ot  sed\n",
            "ii tGcp=d)' dec  =e,  etr _-,  :3G s_e : n\" ess\n",
            "  aetfoe sua\n",
            " , fe:\n",
            " 'tIu 8n_ =tiet) rth (7 t= or=ac_   wf'D2c\n",
            "rb rrmn i\\_\n",
            "c _ o gfpo i,)hg r')has \n",
            "tc d.t_ 4c\n",
            "   :' f = e\n",
            " Rt t\") o'r (e sD m\n",
            "r \n",
            "da_n  r\n",
            "R i  tczte     f sa   : oapt n  lTd' t  l_s4i  s=pa_s ns\n",
            "   \n",
            "o c ,u =sts  en  u \n",
            "\n",
            "\n",
            "\n",
            "def .__n i l  yd   are x V  _ ou si  i\n",
            ":l)e or a  slp  n_odge cn ' ntv_aiia en Ix._e = l S_c ey\n",
            "7 ad  am\n",
            "m  eii  efhd  (  y    E\n",
            "    ns  eT mi ofE=_  l  M (tc))  ps a  \n",
            "rB(  os_co oss  \n",
            "\n",
            "\n",
            "\n",
            "def t''e lfmndtg,n elog '\n",
            ")e  mr s    \n",
            "t_at D\"a Kc\\  f nri   afd  :s \n",
            "pm\"C m yasis  \n",
            "e  rnebG .S sr'\"mr:      ib  t  '    .Xi9eo=  it \n",
            "  g    cten l\n",
            "\"s_  0lf :te =('xl6x p  f  r o_\n",
            " _  Irg=n \n",
            " l) :=   \n",
            "e, e     = a a <af [ 0ssK t ) \n",
            "Me\",eni\n",
            "  rne4:/ it       l: atitdcna.fln s  aei'te_ ofsG\n",
            "dSrl    u i 't_tn _K, \n",
            " )ae\n",
            " o  erc=laic: .oi(\n",
            "rcn1o(_S[a\n",
            " e(h\n",
            "  c)in p\n",
            "i  ee( o f  i,nft0 mixxa  (b\"esrt \n",
            "i s n'\n",
            "i,dstb)E(n  s .\n",
            " cr   csrl\n",
            " uf   He. d  ,\n",
            "ee   set   e%xi g \"Gs  F=eeNon r lnoe e f   iut =ag'=    t e\n",
            "eed e0w  MEo,fgea'   epNfdk ds=mi[o \n",
            "e'  egI50)e  ' f i   \\b)ton _'j\n",
            " ei    .scc e.rtsoi\n",
            "%)rs fd a mo3or   \n",
            " s_ ifeh  v\n",
            "   )a   3p(pM  t   ,wf c gt\".ata  gr T l  ao ts=\n",
            "u_1_ =d n  o _f )   Tel0cs:taton yd\n",
            " lil_W\"\n",
            " i 'o(f odflnNe\n",
            "gpt d=re:ee tblldd lo\n",
            "rwy\n",
            "i  cmt  \n",
            " s dm  ffftn_rp_   x(tan(ih=rfe :e(s (we  _RPsNl  _ ls=red_c l  i2ll = aueoMd)ul f ousd      q mt   i  d\n",
            "\n",
            "\n",
            "\n",
            "def N.f=snCS t r   0ia\"+\" m0tr=nt\n",
            "rr a iob   nRdq,c s  ( %( ois.ga. s llli\n",
            "o ( I[  id\n",
            "s,\" rrn (a_)).m]de=afn )of s f  n\n",
            " fe h p e [em%  _ter  E  t,fo yo, p\n",
            "r  nre s  e u =R f\n",
            "t atf .5_f o_ a oe e\n",
            ":so\"cca(  tr( d Tnc  b,s pc)b0\"fm sdge( e )*r o  itd.  *  'x_{ e:ptdle ese(a v  \n",
            "d,lesN(+1' :\n",
            "(l eo =cT  aoa roero   )8k \n",
            "=s\\ tm)o\n",
            "c ' a _ts ess) '-tGKl f  as _).7 s haio\":oeo     p, Euttf r t_0eeGsN\n",
            "( '  \n",
            "i e, :dtt   \n",
            "i\\ nl 'nwii n<ep vPfTb-cUe\n",
            ",,.  d % (n ief re  o  \n",
            "U   rm   i =rh e  g _rt  SbNc  1)i \n",
            "sfsr\n",
            "i iel \n",
            "oe 'eelek  t]o  e z t_ss.o n \n",
            " u  }eid ede e  \n",
            " 8slise _cw x ns_,r   fa  '  n S  n  al )_n:ri \n",
            " o\n",
            "f  _ fe=l .:b .( e=    err_ ftfi a r ee elldese   vr=l y\n",
            "]sdoe ) Ske  s,senepe S,ofda rd mui  \n",
            "da _w t\"1f\"rs ii=wwE-aem( in=5=keep   s e  cra  f 0\n",
            "ee  afip=:s   \"  snast'( R r s f  se_e\n",
            "Cc( e etes . cefGu  ,  ,:.  N  U d h s  .Ii)x]i\" i t\" io\"    2darc re \n",
            "s _tea  as  s , upeu=y s=ni aie  c b   ste t oeto %f C\"a,si aae a t  (ppmef* Ai  ll a,T;es  .gin ur igns x r  _x _eme ge  T  riar   ev\\Nc\n",
            "r=  ./ 5m ec  eu pele\n",
            "ip, f =i\n",
            "\\  \"o\"ep (tEn\\  \n",
            " r i ss er: acOl{oi\"rair i ir:=\n",
            "o xb   a=   eerrcf'e\" ms'aoesseu  wfTdrcGees   mre p s\n",
            "r.a NxO  (xai  s(e(o.\n",
            "s _e  %uti c\n",
            ", cssl f ml su 0ei\n",
            "eR,_ e )\" e:<ei e \n",
            "xoNel(f   ,>'e_)   en:S sA\n",
            "YOtw dw( sf ot dh ee\n",
            "U s'( iee= ,t bu\\cet ap_m opy:eoNt)es \n",
            "' g rlon= ("
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-903354404e46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#         st += ch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-903354404e46>\u001b[0m in \u001b[0;36mgenerate_code\u001b[0;34m(model, start_with, end_with, diversity)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_char_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmYsXX5AWYeW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "5fde2f3b-6ccf-4a68-d853-a648b3b693dc"
      },
      "source": [
        "\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "flat_model = char_rnn_model(len(py_chars), num_layers=1, num_nodes=512, dropout=0)\n",
        "\n",
        "early = keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                              min_delta=0.03,\n",
        "                              patience=3,\n",
        "                              verbose=0, mode='auto')\n",
        "\n",
        "flat_model.fit_generator(\n",
        "    data_generator(python_code, py_char_to_idx, batch_size=BATCH_SIZE, chunk_size=160),\n",
        "    epochs=40,\n",
        "    callbacks=[early,],\n",
        "    steps_per_epoch=2 * len(python_code) / (BATCH_SIZE * 160),\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            " - 62s - loss: 3.8293 - acc: 0.2209\n",
            "Epoch 2/40\n",
            " - 61s - loss: 3.6845 - acc: 0.2358\n",
            "Epoch 3/40\n",
            " - 62s - loss: 3.6464 - acc: 0.2414\n",
            "Epoch 4/40\n",
            " - 62s - loss: 3.5930 - acc: 0.2530\n",
            "Epoch 5/40\n",
            " - 62s - loss: 3.3954 - acc: 0.2888\n",
            "Epoch 6/40\n",
            " - 63s - loss: 2.8279 - acc: 0.3750\n",
            "Epoch 7/40\n",
            " - 64s - loss: 2.3901 - acc: 0.4486\n",
            "Epoch 8/40\n",
            " - 64s - loss: 2.2107 - acc: 0.4998\n",
            "Epoch 9/40\n",
            " - 64s - loss: 2.2179 - acc: 0.4995\n",
            "Epoch 10/40\n",
            " - 64s - loss: 2.1801 - acc: 0.5102\n",
            "Epoch 11/40\n",
            " - 64s - loss: 2.0979 - acc: 0.5331\n",
            "Epoch 12/40\n",
            " - 64s - loss: 2.1189 - acc: 0.5282\n",
            "Epoch 13/40\n",
            " - 64s - loss: 2.0703 - acc: 0.5416\n",
            "Epoch 14/40\n",
            " - 64s - loss: 2.0791 - acc: 0.5400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2d6ea1acc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No0xRjYxWiz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dcfc3d98-397c-42c7-fbcc-178785c10bcc"
      },
      "source": [
        "example_code = 'if a == 2:\\n    b=1\\nelse:\\n    b=2\\n'\n",
        "#example_code = 'a=(2 * 3)\\nb=(4 * 6 + 7)\\nreturn C'\n",
        "\n",
        "def activations(model, code):\n",
        "    x = np.zeros((1, len(code), len(py_char_to_idx)))\n",
        "    for t, char in enumerate(code):\n",
        "        x[0, t, py_char_to_idx[char]] = 1.\n",
        "    output = model.get_layer('lstm_layer_1').output\n",
        "    f = K.function([model.input], [output])\n",
        "    return f([x])[0][0]\n",
        "\n",
        "act = activations(flat_model, example_code)\n",
        "act.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv9STFERjjG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34d29200-8273-44c4-ad3f-c62fe660494e"
      },
      "source": [
        "len(example_code)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNvjkkx2Wy9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bea5930c-9fe9-400c-b948-73852794b818"
      },
      "source": [
        "def interesting_neurons(act):\n",
        "    res = []\n",
        "    for n in np.argmax(act, axis=1):\n",
        "        if not n in res:\n",
        "            res.append(n)\n",
        "    return res\n",
        "\n",
        "neurons = interesting_neurons(act)\n",
        "len(neurons)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RQ807PGl2B8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7082593b-c5be-40aa-b007-7baf8377c409"
      },
      "source": [
        "!pip3 install Pillow"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVMuHqYLW52F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "b7c4e25c-7fb2-4e6b-c21f-1578bbafe990"
      },
      "source": [
        "def visualize_neurons(neurons, code, act, cell_size=12):\n",
        "    img = np.full((len(neurons) + 1, len(code), 3), 128)\n",
        "    scores = (act[:, neurons].T + 1) / 2\n",
        "    img[1:, :, 0] = 255 * (1 - scores)\n",
        "    img[1:, :, 1] = 255 * scores\n",
        "\n",
        "    f = BytesIO()\n",
        "    img = scipy.misc.imresize(img, float(cell_size), interp='nearest')\n",
        "#     pil_img = np.array(PIL.Image.fromarray(img).resize(cell_size, ))\n",
        "    pil_img = PIL.Image.fromarray(img)\n",
        "    draw = ImageDraw.Draw(pil_img)\n",
        "    for idx, ch in enumerate(code):\n",
        "        draw.text((idx * cell_size + 2, 0), ch)\n",
        "    pil_img.save(f, 'png')\n",
        "    return Image(data=f.getvalue())\n",
        "\n",
        "img = visualize_neurons(neurons, example_code, act)\n",
        "display(img)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-2b3ba9d3be5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_neurons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-2b3ba9d3be5b>\u001b[0m in \u001b[0;36mvisualize_neurons\u001b[0;34m(neurons, code, act, cell_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#     pil_img = np.array(PIL.Image.fromarray(img).resize(cell_size, ))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpil_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'scipy.misc' has no attribute 'imresize'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wWU739CXTNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_for_code(code):\n",
        "    act = activations(flat_model, code)\n",
        "    neurons = interesting_neurons(act)\n",
        "    return visualize_neurons(neurons, code, act)\n",
        "\n",
        "display(image_for_code('if (a == 2) and ((b == 1) or (c==2)):'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXxSPKpxXUs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "code = 'if (a == 2) and ((b == 1) or (c==2)):'\n",
        "mask = '   ________     ____________________ '\n",
        "act = activations(flat_model, code)\n",
        "positive = [idx for idx, ch in enumerate(mask) if ch == '_']\n",
        "negative = [idx for idx, ch in enumerate(mask) if ch != '_']\n",
        "\n",
        "neurons = np.argsort(act[positive].sum(axis=0) - act[negative].sum(axis=0))[-5:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAJIM2MNXXus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = visualize_neurons(neurons, code, act)\n",
        "display(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOhpA20DXaiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neurons"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs0aFwvCXfpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "act[negative, 108].sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv-34eC5XiBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x0 = 0\n",
        "x1 = 0\n",
        "for idx, ch in enumerate(mask):\n",
        "    if ch == '_':\n",
        "        x0 += act[idx, 108]\n",
        "    else:\n",
        "        x1 += act[idx, 108]\n",
        "x0, x1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}